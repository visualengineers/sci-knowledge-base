---
layout: best-practice
title: "Integrating I/O Modalities"
category: technology
lession: 3
image: https://images.unsplash.com/photo-1553936571-6ca616592119?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1950&q=80
image-credits: Photo by <a href="https://unsplash.com/@rtp_atw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Ratapan Anantawat</a> on <a href="/s/photos/led?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>
permalink: /integrating-io-modalities/
---

# Integrating I/O Modalities
Today’s shape-changing interfaces typically focus on shape input and output, with less emphasis on other modalities—for instance, visual output is often realised by projection mapping or low resolution LEDs. While this is acceptable for early research prototypes, successful real-world interfaces will demand additional input and output modalities. This includes high-resolution touch sensing, in-place visual output, adjustable material properties and accurate sensing of the device’s physical shape. Without this core integration, shapechanging interfaces will fail to realise their full potential.

<details markdown="1" open>
<summary><h3>Examples</h3></summary> 
There is no example yet. Feel free to <a href="{{ site.repo }}/edit/master/{{ page.path }}" target="_blank"><i class="fa fa-edit fa-fw"></i> edit this page</a>.
</details>

