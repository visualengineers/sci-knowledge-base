<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.55.6" />

<META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">

<link rel="alternate" type="application/rss&#43;xml" href="/docs/index.xml">

<link rel="shortcut icon" href="/sci-knowledge-base/assets/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/sci-knowledge-base/assets/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/android-96x196.png" sizes="96x196">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/sci-knowledge-base/assets/favicons/android-192x192.png"sizes="192x192">

<title>Search</title>
<meta property="og:title" content="Search" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://localhost:4000" />
<meta property="og:site_name" content="http://localhost:4000" />

<meta itemprop="name" content="Search">
<meta itemprop="description" content="">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Search"/>
<meta name="twitter:description" content=""/>

<link rel="stylesheet" href="/sci-knowledge-base/assets/css/main.css">
<link rel="stylesheet" href="/sci-knowledge-base/assets/css/palette.css">
<link rel="stylesheet" href="/sci-knowledge-base/assets/css/custom.css">
<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>
</head>

  

  <body class="td-section">
    <header>
        <nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/sci-knowledge-base/">
            <span class="navbar-logo"></span><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149v0 0zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zM197.0804 232.033c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><path style="fill:#5b7fc0" d="M198.8952 225.1043h122.6266v13.8671H198.8952z"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zM197.0804 177.6188c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><path style="fill:#d95140" d="M198.8952 170.69h122.6266v13.8671H198.8952z"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zM197.5309 286.4723c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><path style="fill:#56a55c" d="M199.3456 279.5436h122.6266v13.8671H199.3456z"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032-4.13-4.1299-6.4032-9.6186-6.4056-15.4628.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zM197.0804 340.5784c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><path style="fill:#f1bc42" d="M198.8952 333.6497h122.6266v13.8671H198.8952z"/></g></g></svg>
<span class="font-weight-bold">SCI KNOWLEDGE BASE</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="overflowX-scroll mobile-nav navbar-nav mt-2 mt-lg-0">
			<li class="nav-item mr-4 mb-2 mb-lg-0">
          <a class="nav-link" href="/sci-knowledge-base/index" ><span>About</span></a>
			</li>
			<li class="nav-item mr-4 mb-2 mb-lg-0">
          <a class="nav-link" href="/sci-knowledge-base/index/#modules" ><span>Modules</span></a>
			</li>
			<li class="nav-item mr-4 mb-2 mb-lg-0">
          <a class="nav-link" href="/sci-knowledge-base/topics" ><span>Topics</span></a>
			</li>
			<li class="nav-item mr-4 mb-2 mb-lg-0">
          <a class="nav-link" href="/sci-knowledge-base/resources" ><span>Resources</span></a>
			</li>
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block">
      <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
  </div>


      </div>


</nav>
</header>

<script>
$(document).ready(function() {
  var url = "https://api.github.com/search/repositories?q=elenalenaelena/visualengineers/sci-knowledge-base";
  fetch(url, { 
      headers: {"Accept":"application/vnd.github.preview"}
  }).then(function(e) {
    return e.json()
  }).then(function(r) {
     console.log(r.items[0])
     stars = r.items[0]['stargazers_count']
     forks = r.items[0]['forks_count']
     $('#stars').text(stars + " Stars")
     $('#forks').text(forks + " Forks")
  });
});
</script>

    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
          <div id="td-sidebar-menu" class="td-sidebar__inner">  
  <nav class="collapse td-sidebar-nav pt-2 pl-4" id="td-section-nav">
  
  
  <ul class="td-sidebar-nav__section pr-md-3">
    <li class="td-sidebar-nav__section-title">
      <a  href="/sci-knowledge-base/index" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">About</a>
    </li>

    
  </ul>
  
  <ul class="td-sidebar-nav__section pr-md-3">
    <li class="td-sidebar-nav__section-title">
      <a  href="/sci-knowledge-base/topics" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Topics</a>
    </li>

    
      <ul>
      <li class="collapse show" id="topics">
          <ul class="td-sidebar-nav__section pr-md-3">
            
            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/design" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Design</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/society" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Society</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/technology" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Technology</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/user-experience" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">User Experience</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            

          </ul>
        </li>
      </ul>
    
  </ul>
  
  <ul class="td-sidebar-nav__section pr-md-3">
    <li class="td-sidebar-nav__section-title">
      <a  href="/sci-knowledge-base/index" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Modules</a>
    </li>

    
      <ul>
      <li class="collapse show" id="modules">
          <ul class="td-sidebar-nav__section pr-md-3">
            
            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/terms" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Terms</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/concepts" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Concepts</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/best-practices" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Best Practices</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            

          </ul>
        </li>
      </ul>
    
  </ul>
  
  <ul class="td-sidebar-nav__section pr-md-3">
    <li class="td-sidebar-nav__section-title">
      <a  href="/sci-knowledge-base/workshop-builder" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Workshop</a>
    </li>

    
      <ul>
      <li class="collapse show" id="workshop">
          <ul class="td-sidebar-nav__section pr-md-3">
            
            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/workshop-builder" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Workshop Builder</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            
            <li class="td-sidebar-nav__section-title">
              <a href="/sci-knowledge-base/interviews/workshops" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Interview</a>
            </li>

            <ul>
              <li class="collapse show" id="">
                
                
              </li>
            </ul>

            

          </ul>
        </li>
      </ul>
    
  </ul>
  
  <ul class="td-sidebar-nav__section pr-md-3">
    <li class="td-sidebar-nav__section-title">
      <a  href="/sci-knowledge-base/resources" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Resources</a>
    </li>

    
  </ul>
  
  <ul class="td-sidebar-nav__section pr-md-3">
    <li class="td-sidebar-nav__section-title">
      <a  href="/sci-knowledge-base/news" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">News</a>
    </li>

    
  </ul>
  
  
  </nav>
</div>

          </div>
          <div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
              <div class="td-page-meta ml-2 pb-1 pt-2 mb-0">
                  <a href="https://github.com/visualengineers/sci-knowledge-base/edit/master/pages/search.html" target="_blank"><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/visualengineers/sci-knowledge-base/issues/new?labels=question&title=Question:&body=Question on: https://github.com/visualengineers/sci-knowledge-base/tree/master/pages/search.html" target="_blank"><i class="fab fa-github fa-fw"></i> Create documentation issue</a>
<a href="https://github.com/visualengineers/sci-knowledge-base/issues/new" target="_blank"><i class="fas fa-tasks fa-fw"></i> Create project issue</a>
<!-- this will parse through the header fields and add a button to open
     an issue / ask a question on Github. The editable field should be in
     the post frontend matter, and refer to the label to open the issue for -->

              </div>
              <nav id="TableOfContents"><ul>
              <li><ul id="TOC">
                <!-- Links will be appended here-->
              </ul></li>
              </ul></nav>
          </div>
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
           <div class="td-content">
	      <input class="form-control td-search-input" type="search" name="q" id="search-input" placeholder="&#xf002 Search this site…"  style="margin-top:5px" autofocus>
<i style="color:white; margin-right:8px; margin-left:5px" class="fa fa-search"></i>

<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>

<ul id="search-results"></ul>

<script>
	window.data = {
		
		
				
					
					
					"archive": {
						"id": "archive",
						"title": "Articles",
						"categories": "",
						"url": " /archive/",
						"content": "News Archive\n\n2019\n\n\n  Dec 10, 2019: Daten zum Anfassen"
					}
					
				
		
				
					,
					
					"best-practices": {
						"id": "best-practices",
						"title": "Best Practices",
						"categories": "",
						"url": " /best-practices/",
						"content": "Best Practices\n\nBest Practices cover practical challenges that may arise during the design process of shape-changing interfaces. To help you get started they are grouped into 4 major topics: Technology, User Experience, Design and Society.\n\nRead about a specific challenge and why it is important and what ways you have to overcome it. Additional workshop instructions help you to quickly train your aquired knowledge in practice. You are invited to publish the results of your workshops or to create your own best practice.\n\ndesign\n\n\n\n\n    \n        \n        Design Prototyping\n    \n\n\n\n    \n        \n        Designing Application and Content\n    \n\n\n\n    \n        \n        Designing for Temporality\n    \n\n\n\n    \n        \n        Integrating Artefact and Interaction\n    \n\n\n\n\nsociety\n\n\n\n\n    \n        \n        Developing Sustainable Interfaces\n    \n\n\n\n    \n        \n        Legislating Technological Innovation\n    \n\n\n\n\ntechnology\n\n\n\n\n    \n        \n        Combining Miniturization With Resolution\n    \n\n\n\n    \n        \n        Considering Non-functional Requirements\n    \n\n\n\n    \n        \n        Integrating I/O Modalities\n    \n\n\n\n    \n        \n        Using Toolkits for Prototyping\n    \n\n\n\n\nuser experience\n\n\n\n\n    \n        \n        Identifying Contexts of Use\n    \n\n\n\n    \n        \n        Understanding UX Factors\n    \n\n\n\n\n\n    \n    \n\n\n\nAre you looking for technical terms, methods and background knowledge? See the collection of Terms and Concepts."
					}
					
				
		
				
					,
					
					"concepts": {
						"id": "concepts",
						"title": "Concepts",
						"categories": "",
						"url": " /concepts/",
						"content": "Concepts\n\nConcepts assist you in the development of any kind of shape-changing interface by giving you an overview over different techniques or explaning a transferable method. Additionally, concepts may provide workshop material. \nFeel free to share your own knowledge!\n\n\n\ndesign\n\n\n\n\n    \n            \n                \n            \n          Chart Types\n      \n\n\n\n    \n            \n                \n            \n          Color Theory\n      \n\n\n\n    \n            \n                \n            \n          Materiality\n      \n\n\n\n    \n            \n                \n            \n          Mood Board\n      \n\n\n\n    \n            \n                \n            \n          Paper Prototyping\n      \n\n\n\n    \n            \n                \n            \n          Stop Motion\n      \n\n\n\n\ntechnology\n\n\n\n\n    \n            \n                \n            \n          Emulator\n      \n\n\n\n    \n            \n                \n            \n          Projection\n      \n\n\n\n    \n            \n                \n            \n          REFLEX Software Framework\n      \n\n\n\n    \n            \n                \n            \n          Tracking\n      \n\n\n\n\nuser experience\n\n\n\n\n    \n            \n                \n            \n          Gestalt Principles\n      \n\n\n\n    \n            \n                \n            \n          Gesture Alphabet\n      \n\n\n\n    \n            \n                \n            \n          Tasks\n      \n\n\n\n    \n            \n                \n            \n          Persona\n      \n\n\n\n    \n            \n                \n            \n          Scenario\n      \n\n\n\n\nsociety\n\n\n\n\n    \n            \n                \n            \n          Sustainability\n      \n\n\n\n\n\n    \n    \n\n\n\nAre you facing a tricky challenge or looking for practical applications? See the collection of Best Practices."
					}
					
				
		
				
					,
					
					"design": {
						"id": "design",
						"title": "design",
						"categories": "",
						"url": " /design/",
						"content": ""
					}
					
				
		
				
					,
					
					"docs": {
						"id": "docs",
						"title": "Documentation",
						"categories": "",
						"url": " /docs/",
						"content": "Documentation\n\nWelcome to the Elastic Displays Wiki!"
					}
					
				
		
				
					,
					
					"feed-xml": {
						"id": "feed-xml",
						"title": "",
						"categories": "",
						"url": " /feed.xml",
						"content": "Shape-changing Interfaces Knowledge Base\n    \n    http://localhost:4000/sci-knowledge-base/\n    \n    Tue, 16 Feb 2021 15:05:23 +0100\n    Tue, 16 Feb 2021 15:05:23 +0100\n    Jekyll v3.8.5\n    \n      \n        Daten zum Anfassen\n        &lt;p&gt;Das Forschungsprojekt ZELASTO erforscht die Darstellung von und Interaktion mit komplexen Daten auf elastischen Displays. Verschiedene Anwendungsfälle zeigen, wie wissenschaftliche Erkenntnisse zu neuartigen Displaytechnologien in produktiven Industriekontexten zum Einsatz kommen können.&lt;/p&gt;\n\n&lt;!--more--&gt;\n\n&lt;p&gt;Spracheingabe und intuitiv nutzbare Multi-Touch-Displays sind mittlerweile im Alltag angekommen. Die neuen Interaktionstechniken sind aber noch lange nicht das Ende der Fahnenstange: Displayformen der Zukunft nutzen vor allem biegbare und verformbare Materialien wie Papier, Stoff oder flexible Kunststoffe. Über die physischen Zustände dieser Materialien können mehr Informationen transportiert werden. Damit eröffnen sich neuartige Möglichkeiten, um komplexe, multidimensionale Datenräume zu erforschen. Innovative Displaytechnologien wie beispielsweise elastische Displays aus Stoff oder Gel zielen auf einer natürliches und intuitives Benutzererlebnis ab, indem das System direktes haptisches Feedback zur Interaktion und ihren Auswirkungen auf die dargestellten Daten liefert.&lt;/p&gt;\n\n&lt;p&gt;Im Forschungs- und Entwicklungsprojekt ZELASTO - Interaktion mit komplexen Daten mittels Zoomable User Interfaces auf Elastischen Oberflächen kooperiert die Professur für Technische Visualistik der HTW Dresden mit der GTV – Gesellschaft für Technische Visualistik mbH in Dresden.  Der GTV gelingt seit dem Jahr 2018 der produktive Dauereinsatz eines Tisches mit elastischer Interaktionsoberfläche im Heinz-Nixdorf-MuseumsForum in Paderborn.  Ziel des Kooperationsprojektes ZELASTO ist es, wissenschaftliche Erkenntnisse zur Interaktion und Steuerung elastischer Multitouch-Displays in industriellen Arbeitsprozessen zu nutzen. Gemeinsam werden Einsatzmöglichkeiten der innovativen Technologie für gleich zwei Anwendungsfälle aus Stadtplanung und Maschinenbau an Demonstratoren erprobt. Zentrale Forschungsthemen sind die Interaktion mit komplexen Daten sowie die Steuerung von Zoomable User Interfaces (ZUI) durch Verformung von Oberflächen. Das zweijährige Projekt wird im Rahmen des Schwerpunkts “Stärkung von Forschung, technologischer Entwicklung und Innovation” von der SAB mit Mitteln aus dem Europäischen Fonds für regionale Entwicklung (EFRE) gefördert. Im Anschluss an die Projektlaufzeit ist eine Weiterentwicklung und Generalisierung des Produkts zur Serienreife vorgesehen.&lt;/p&gt;\n\n\n        Tue, 10 Dec 2019 01:00:01 +0100\n        http://localhost:4000/sci-knowledge-base/2019/daten-zum-anfassen/\n        http://localhost:4000/sci-knowledge-base/2019/daten-zum-anfassen/\n        \n        \n        project"
					}
					
				
		
				
					,
					
					"": {
						"id": "",
						"title": "About SCI-KB",
						"categories": "",
						"url": " /",
						"content": "About SCI-KB\n\nThe Shape-Changing Interfaces Knowledge Base (SCI-KB) originates from the research project ZELASTO which explores the interaction with complex data using Zoomable User Interfaces on Elastic Displays. We aim to spread recent knowledge on the research of shape-changing interfaces (SCI) both theoretically and practically. Modular knowledge items can be combined arbitrarily, e.g. to hold workshops. A Workshop Builder provides assistance in finding an individual arrangement. The core of knowledge is supplemented by additional resources and structured by tags which reflect various topics in the interdisciplinary field of shape-changing interfaces.\n\n\n\n\n  Topics\n\n  Browse topics to discover knowledge items in one of the 4 essential topics related to the field of shape-changing interfaces. The topics can also be interpreted as states of development.\n\n  \n\n\ndesign\n\nsociety\n\ntechnology\n\nuser experience\n\n\n  \n\n\n\n\n  Knowledge Modules\n\n  Depending on the type of knowledge they contain, smaller knowledge items are assigned one of the modules Terms, Concept or Best Practices (see picture). The modules each pervade the three conceptual levels “Learn”, “Apply” and “Contribute”. Thus, exploring items within a module provides an alternative path to the topic-based approach.\n\n  \n\n  Term. On the “Learn” level, each term explains a technical term for shape-changing interfaces, for example “Elastic Display”. On the “Apply” level, examples show how the term is used in practice. The “Contribute” level invites users to modify or add terms.\n\n  Concept. In the style of a cheat sheet, each concept explains on the “Learn” level an application-independent principle that can be useful for the implementation of a shape-changing interface. This includes, for example, design guidelines, overviews of chart types and data types or a gesture catalogue for interaction with elastic displays. On the “Apply” level, a Concept provides workshop material. Analogous to a Term, a Concept can be modified or created at the “Contribute” level.\n\n  Best Practice. On the “Learn” level, a best practice explains a practical challenge that may arise in the design process of shape-changing interfaces, such as the choice of a suitable prototyping technology, and shows ways to overcome the challenge. On the “Apply” level, there are suggestions on how to train the solutions in a workshop using materials provided by the Concepts particularly. Workshop participants are invited to publish the results of their workshops on the “Contribute” level or to create their own best practice.\n\n\n\n\n  Workshop Builder\n\n  With the Workshop Builder, modular workshops tailored to the custom needs can be composed from the knowledge items. Therefore, the starting point for a practical walkthrough through SCI-KB that is based on the context of the workshop and its objectives is suggested. The walktrough may be thematic, problem- or topic-oriented, a deep-dive into specific knowledge or explorative. Start planning your workshop.\n\n\n\nSupport\n\nIf you need help, please don’t hesitate to open an issue."
					}
					
				
		
				
		
				
					,
					
					"assets-js-main-js": {
						"id": "assets-js-main-js",
						"title": "",
						"categories": "",
						"url": " /assets/js/main.js",
						"content": "(function($) {\n    'use strict';\n    $(function() {\n        $('[data-toggle=\"tooltip\"]').tooltip();\n        $('[data-toggle=\"popover\"]').popover();\n        $('.popover-dismiss').popover({\n            trigger: 'focus'\n        })\n    });\n\n    function bottomPos(element) {\n        return element.offset().top + element.outerHeight();\n    }\n    $(function() {\n        var promo = $(\".js-td-cover\");\n        if (!promo.length) {\n            return\n        }\n        var promoOffset = bottomPos(promo);\n        var navbarOffset = $('.js-navbar-scroll').offset().top;\n        var threshold = Math.ceil($('.js-navbar-scroll').outerHeight());\n        if ((promoOffset - navbarOffset) < threshold) {\n            $('.js-navbar-scroll').addClass('navbar-bg-onscroll');\n        }\n        $(window).on('scroll', function() {\n            var navtop = $('.js-navbar-scroll').offset().top - $(window).scrollTop();\n            var promoOffset = bottomPos($('.js-td-cover'));\n            var navbarOffset = $('.js-navbar-scroll').offset().top;\n            if ((promoOffset - navbarOffset) < threshold) {\n                $('.js-navbar-scroll').addClass('navbar-bg-onscroll');\n            } else {\n                $('.js-navbar-scroll').removeClass('navbar-bg-onscroll');\n                $('.js-navbar-scroll').addClass('navbar-bg-onscroll--fade');\n            }\n        });\n    });\n}(jQuery));\n(function($) {\n    'use strict';\n    var Search = {\n        init: function() {\n            $(document).ready(function() {\n                $(document).on('keypress', '.td-search-input', function(e) {\n                    if (e.keyCode !== 13) {\n                        return\n                    }\n                    var query = $(this).val();\n                    var searchPage = \"/sci-knowledge-base/search/?q=\" + query;\n                    document.location = searchPage;\n                    return false;\n                });\n            });\n        },\n    };\n    Search.init();\n}(jQuery));"
					}
					
				
		
				
					,
					
					"news": {
						"id": "news",
						"title": "News",
						"categories": "",
						"url": " /news/",
						"content": "News\n\nSubscribe with RSS to keep up with the latest news.\nFor site changes, see the changelog kept with the code base.\n\n\n\n\n   Daten zum Anfassen\n   December 10, 2019\n   technology-badgeux-badgedesign-badgesociety-badge\n   Das Forschungsprojekt ZELASTO erforscht die Darstellung von und Interaktion mit komplexen Daten auf elastischen Displays. Verschiedene Anwendungsfälle zeigen, wie wissenschaftliche Erkenntnisse zu neuartigen Displaytechnologien in produktiven Industriekontexten zum Einsatz kommen können.\n\n\n   \n      read more\n   \n   \n\n\nWant to see more? See the News Archive."
					}
					
				
		
				
					,
					
					"resources": {
						"id": "resources",
						"title": "Resources",
						"categories": "",
						"url": " /resources/",
						"content": "Resources\nadditional resources related to the research on Elastic Displays\n\n\n  Interviews\n\n  \n\n    Interview with Franziska Hannß on Holding Workshops: \"Intensive social exchange enables a deep common understanding of the facts.\"\n\n\n\n\n\n\n\n\n\n  References\n\n  \n\n\n\n    [1] Alexander, J., Roudaut, A.,Steimle, J., Hornbæk, K., Bruns Alonso, M., Sean Follmer, S., Merritt, T. (2018). Grand Challenges in Shape-Changing Interface Research. In: CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems.  https://doi.org/10.1145/3173574.3173873\n\n\n\n\n    [2] Hornbæk, K., Bederson, B. B., Plaisant, C. (2002). Navigation Patterns and Usability of Zoomable User Interfaces With and Without an Overview. In: Publication: ACM Transactions on Computer-Human Interaction (TOCHI).  https://doi.org/10.1145/586081.586086\n\n\n\n\n    [3] Hummels, C., Smets, G., Overbeeke, K. (1997). An Intuitive Two-Handed Gestural Interface for Computer Supported Product Design. In: LNCS, volume 1371.  https://doi.org/10.1007/BFb0053000\n\n\n\n\n    [4] Ishii, H., Ullmer, B. (1997). Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms. In: CHI '97: Proceedings of the ACM SIGCHI Conference on Human factors in computing systems.  https://doi.org/10.1145/258549.258715\n\n\n\n\n    [5] Kammer, D., Gründer, T, Göbel, F.,  Groh, R. (2014). Investigating Gestures on Elastic Tabletops. In: TEI’14.  https://www.semanticscholar.org/paper/Investigating-Gestures-on-Elastic-Tabletops-Kammer/b7978c5315ae9544491b0f933b318c9a747cfa23\n\n\n\n\n    [6] Kammer, D., Müller, M., Wojdziak, J.,  Franke, I. S. (2018). New Impressions in Interaction Design. A Task Taxonomy for Elastic Displays. In: i-com: Vol. 17, No. 3.  https://doi.org/10.1515/icom-2018-0021\n\n\n\n\n    [7] Krathwohl, D.R. (2002). A revision of bloom’s taxonomy: An overview. . In: Theory Into Practice 41(4),  212–218.  https://doi.org/10.1207/s15430421tip41042,https://doi.org/10.1207/s15430421tip4104_2\n\n\n\n\n    [8] Kurtenbach, G. and Hulteen, E.A. (1990) Gestures in Human-Computer Communication. (1990). Gestures in Human-Computer Communication. In: In: Laurel, B., Ed., The Art of Human-Computer Interface Design, Addison-Wesley Publishing Company, Inc., New York..  https://doi.org/10.1145/1349026.1349033\n\n\n\n\n    [9] Lahey, B., Girouard, A., Burleson, W., Vertegaal R. (2011). PaperPhone: Understanding the Use of Bend Gestures in Mobile Devices with Flexible Electronic Paper Displays!. In: CHI '11: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems.  https://doi.org/10.1145/1978942.1979136\n\n\n\n\n    [10] Luciani, A. (2014). Ergotic / epistemic / semiotic functions. In: Enaction and Enactive Interfaces: A Handbook of Terms.  https://hal.archives-ouvertes.fr/hal-00979975/document\n\n\n\n\n    [11] McNeil, D. (1992). Gesture: A Psycholonguistic Appraoch. In: Psycholinguistics Section, The Encyclopedia of Language and Linguistics.  https://doi.org/10.1.1.541.1430\n\n\n\n\n    [12] Miruchna, V., Walter, R., Lindlbauer, D., Lehmann, M., von Klitzing, R., Müller, J. (2015). GelTouch: Localized Tactile Feedback Through Thin, Programmable Gel. In:  UIST '15: Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology.  https://doi.org/10.1145/2807442.2807487\n\n\n\n\n    [13] Muser, S. (2015). Gestures in Human-Computer-Interaction. In: Research Paper in Media Informatics Proseminar LMU München.  https://www.medien.ifi.lmu.de/lehre/ss15/ps/papers/Muser-GesturesInHCI.pdf\n\n\n\n\n    [14] Nielsen, L. (2013). Personas. In: The Encyclopedia of Human-Computer Interaction, 2nd Ed..  https://www.interaction-design.org/encyclopedia/personas.html\n\n\n\n\n    [15] Peschke, J. Göbel, F., Groh, R. (2012). DepthTouch: Elastische Membran zwischen virtuellem und realem Raum. In: AVI '12: Proceedings of the International Working Conference on Advanced Visual Interfaces.  https://doi.org/10.1145/2254556.2254706\n\n\n\n\n    [16] Sturdee, M., Alexander, J. (2018). Analysis and Classification of Shape-Changing Interfaces for Design and Application-based Research. In: ACM Computing Surveys (CSUR).  https://doi.org/10.1145/3143559\n\n\n\n\n    [17] Troiano, G. M., Pedersen, E. W., Hornbæk, K. (2014). User-Defined Gestures for Elastic, Deformable Displays. In: Conference: AVI 2014.  https://doi.org/10.13140/2.1.2396.6083\n\n\n\n\n    [18] Ullmer, B., Ishii, H., Jacob R. J. K. (2005). Token+constraint systems for tangible interaction with digital information. In: ACM Transactions on Computer-Human Interaction (TOCHI).  https://doi.org/10.1145/1057237.1057242\n\n\n\n\n    [19] Vertegaal, R., Poupyrev, I. (2008). Organic User Interfaces. In: Communications of the ACM.  https://doi.org/10.1145/1349026.1349033\n\n\n\n\n\n\n\n  External Links\n\n  \n\n\n    Cheat Sheets for Visualization Techniques. https://visualizationcheatsheets.github.io/\n\n\n\n    DESIGNPILOT. https://app.designpilot.io/lexicon\n\n\n\n    Gestures - Google Material Design. https://material.io/design/interaction/gestures.html\n\n\n\n    Git-flow-Workflow. https://www.atlassian.com/de/git/tutorials/comparing-workflows/gitflow-workflow\n\n\n\n    Mudpad: Fluid Haptics for Touch Surfaces, Media Computing Group, RWTH Aachen . https://hci.rwth-aachen.de/mudpad\n\n\n\n    Obake: interactions with a 2.5D elastic display. https://vimeo.com/63494095\n\n\n\n    Tangible Media Group. http://tangible.media.mit.edu\n\n\n\n    visualizingdata.com. https://www.visualisingdata.com/resources/"
					}
					
				
		
				
		
				
		
				
					,
					
					"sitemap-xml": {
						"id": "sitemap-xml",
						"title": "",
						"categories": "",
						"url": " /sitemap.xml",
						"content": "/\n     {{ \"now\" | date: \"%Y-%m-%d\" }}\n     daily\n    \n{% for section in site.data.toc %}\n     {{ site.baseurl }}{{ section.url }}/\n     {{ \"now\" | date: \"%Y-%m-%d\" }}\n     daily\n    \n{% endfor %}"
					}
					
				
		
				
					,
					
					"society": {
						"id": "society",
						"title": "society",
						"categories": "",
						"url": " /society/",
						"content": ""
					}
					
				
		
				
					,
					
					"tags": {
						"id": "tags",
						"title": "Tags Index",
						"categories": "",
						"url": " /tags/",
						"content": "Tags Index\n{% capture site_tags %}{% for tag in site.tags %}{% if tag %}{{ tag | first }}{% unless forloop.last %},{% endunless %}{% endif %}{% endfor %}{% endcapture %}{% assign docs_tags = \"\" %}{% for doc in site.docs %}{% assign ttags = doc.tags | join:',' | append:',' %}{% assign docs_tags = docs_tags | append:ttags %}{% endfor %}\n{% assign all_tags = site_tags | append:docs_tags %}{% assign tags_list = all_tags | split:',' | uniq | sort %}\n\n{% for tag in tags_list %}{% if tag %}{{ tag }}\n\n    {% for post in site.tags[tag] %}\n    {{- post.title -}}\n     {{- post.date | date: \"%B %d, %Y\" -}}\n{%- endfor -%}\n{% for doc in site.docs %}{% if doc.tags contains tag %}\n\n    {{ doc.title }}\n         {{- doc.date | date: \"%B %d, %Y\" -}}\n    {% endif %}{% endfor %}\n{% endif %}{%- endfor -%}"
					}
					
				
		
				
					,
					
					"technology": {
						"id": "technology",
						"title": "technology",
						"categories": "",
						"url": " /technology/",
						"content": ""
					}
					
				
		
				
					,
					
					"terms": {
						"id": "terms",
						"title": "Terms",
						"categories": "",
						"url": " /terms/",
						"content": "# {{ page.title }}\n\n{{ page.description }} \nFeel free to share your own knowledge!  \n\n{% assign groups = site.terms | group_by: \"category\" %}\n\n{% for group in groups %}\n{{ group.name }} \n\n\n{% for item in group.items %}\n\n    {{ item.title }}\n\n{%endfor%}\n\n\n{%endfor%}\n\n\n    \n    {% for post in site.docs  %}        \n    \n    {{ post.title }}\n    {{ post.description }}\n    {% endfor %}\n\n\n\nAre you facing a tricky challenge or looking for practical applications? See the collection of Best Practices."
					}
					
				
		
				
					,
					
					"topics": {
						"id": "topics",
						"title": "Topics",
						"categories": "",
						"url": " /topics/",
						"content": "# {{ page.title }}\n\nTopics describe 4 essential topics related to the field of shape-changing interfaces. The topics can also be interpreted as states of development.\n\n\n\n{% assign topics = site.pages | where: \"layout\", \"topic\" %}\n\n\n\n{% for item in topics %}\n\n{% assign terms = site.terms | where: \"category\", item.title %}\n{% assign concepts = site.concepts | where: \"category\", item.title %}\n{% assign best-practices = site.best-practices | where: \"category\", item.title %}\n\n\n{{ item.title}}\n{{ item.description }}\n{{ terms.size }} Terms / {{concepts.size }} Concepts / {{ best-practices.size }} Best Practices\n\n\n{% endfor %}"
					}
					
				
		
				
					,
					
					"user-experience": {
						"id": "user-experience",
						"title": "user experience",
						"categories": "",
						"url": " /user-experience/",
						"content": ""
					}
					
				
		
				
					,
					
					"workshop-builder": {
						"id": "workshop-builder",
						"title": "Workshop Builder",
						"categories": "",
						"url": " /workshop-builder",
						"content": "# Workshop Builder\nThe Workshop Builder **helps you plan and prepare workshops that fit your needs**. You may use it in advance of each workshop as the preliminary questions are always the same and the tips and tools are reusable. First of all, it is important to know the context and goal of the workshop. Next, the basic procedure can be determined and the appropriate knowledge items can be arranged. \n\n## Customize Your Workshop\nAnswer the following questions to get your personal suggestions for knowledge items you can pick from. You will find workshop material and further instructions within each chosen knowledge item.\n\n\n\n\n        \n        Define your aim\n        This is just to let you get focused. Describe your goal as short and precise as possible. If you are stuck, perhaps the S.M.A.R.T. criteria or an “is not” analysis (excluding everything that is not the objective) will help.   \n        \n        \n    \n    \n        What's the number of participants?\n        \n        group\n        \n        individual       \n    \n       \n        Where are you working from?\n        \n        same place\n        \n        distributed\n    \n    \n         Choose a statement. I am / We are ...\n        \n        at a certain development stage / interested in a certain topic.\n        \n        facing a complex challenge and don't know where to start.\n        \n        missing some theoretical background in design and implementation techniques.\n        \n        looking for practical knowledge within a specific research field / keyword.\n        \n        interested in everything or have multiple problems.\n        create plan\n    \n\n\n\n\n\nYour Workshop Plan\n\n\n\n\n\n       \n        Your Aim\n        \n            \n        \n        \n            You didn't define an aim so far.\n            Have a look at the S.M.A.R.T. criteria or try doing an “is not” analysis (excluding everything that is not the objective). \n        \n    \n        \n        Participants\n        \n            You are working in a team.\n        \n         \n            Your are working on your own.\n        \n    \n      \n        Workplace\n        \n        You are working at the same place.\n        Read our interview with interview with Franziska to get some valuable tips for holding your workshop.\n        \n        \n        You are working distributed.\n        Do you already know miro? We think its a very powerful tool. \n        You can work on online whiteboards together or sort out your ideas individually. \n        \n    \n     \n        Challenge\n         \n            You are at a certain development stage / interested in a certain topic.\n            We recommend a thematic walktrough. Pick from the knowledge items within topic you are interested in.\n        \n        \n        You are facing a complex challenge and don't know where to start.\n        We recommend a problem-oriented walktrough. Search all Best Practices and pick the knowledge items you are interested in.\n        \n        \n        You are missing some theoretical background in design and implementation techniques.\n        We recommend a technology-oriented walktrough. Search concepts.\n        \n        \n        You are looking for practical knowledge within a specific research field / keyword.\n        We recommend a deep-dive approach. Search by Keyword or browse terms.\n        \n        \n        \n        You are interested in everything or have multiple problems.\n        We recommend an explorative walktrough. Take a nap, start at the beginning of the page or let your cat browse SCI-KB.\n        \n        \n            no answer\n        \n    \n\n\nreset plan\n\n\n\n\n\n\nNot sure if you want to hold a workshop? Have a look at our interview on holding workshops."
					}
					
				
		
				
		
		
				
					,
					
					"terms-3d-printing": {
						"id": "terms-3d-printing",
						"title": "3D Printing",
						"categories": "technology",
						"url": " /terms/3D-printing",
						"content": "3D printing is the manufactoring process of making three dimensional solid objects from a  three-dimensional digital model.  It is a commonly used prototyping technique to be able to go to market faster. \nBased on the instructions in the printing file a 3D printing machine lays down thin layers of a material in succession. Therefore it is also known as additive manufactoring. Printing techniques and materials vary, the cheapest and most common being Fusion Deposition Modeling (FDM) with colorful ABS plastic. However, 3D printers can also print nylon and resins, metals or ceramic in a more detailed and durable way using techniques like for example Stereolithography (SLA), Jetting Processes or Selective Laser Sintering (SLS).\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-actuated-display": {
						"id": "terms-actuated-display",
						"title": "Actuated Display",
						"categories": "technology",
						"url": " /terms/actuated-display",
						"content": "Actuated displays are shape-changing interfaces with active deformation property. Most of the existing actuated display implementations are tabletop dislays with a surface that is malleable through direct touch input or freehand gestures. Motorized pins controlled individually by a computer algorithm create the shape of the display. Front or rear projection is used to render visual output on the surface. In constrast to this approach, other applications use shape memory alloys and a capacitive sensor for actuation and interaction. Direct light emission with integrated LEDs creates the visualization.\n\nOne of the main limitations of actuated display techniques is the mechanical complexity, resulting in high realization costs. Amoung a huge range of research prototypes therefore only few commercial displays (such as Braille displays for visually impaired people) exist.\n\n\n  Examples\n\n  The TableHop tabletop display provides self-actuated deformation and vibro-tactile feedback in combination with high-resolution rear projection. Frequency modulation in the high-voltage circuit allows to sense where the user’s fingertip touches the surface. To create surface deformations up to ±5 mm, spandex fabric is electrostatically actuated using transparent indium tin oxide electrodes on its underside.\n\n  \n\n  inFORM is a Dynamic Shape Display that renders digital 3D content and allows unsers to interact with it in a tangible way. inFORM can also interact with the physical world around it, for example moving objects on the table’s surface. Remote participants can be displayed physically, allowing the ability to interact physically at a distance.\n\n  \n  \n\n  Relief is an actuated tabletop display, which is able to render and animate 3D shapes with a malleable surface. Users can experience and form digital models projected on the surface (e.g. geographical terrain) in an intuitive manner. 120 motorized pins, controlled with low-cost, open-source platforms, actuate the surface. Each pin can be addressed individually and senses user input like pulling and pushing.\n\n  Lumen is an interactive display that presents visual images and physical moving shapes, both controlled independently using shape mempry alloys and a capacitive sensor.  Users interact with Lumen directly, forming shapes and images with their hands. The smooth, organic physical motions provide aesthetically pleasing, calm displays for ambient computing environments."
					}
					
				
		
				
					,
					
					"terms-conductive-material": {
						"id": "terms-conductive-material",
						"title": "Conductive Material",
						"categories": "technology",
						"url": " /terms/conductive-material",
						"content": "Every material is conducting, it’s only a matter of how what potential difference has to be applied. Relativly high conductive materials like metals are often used as in touch screen surfaces because they can convert a finger’s movement into a computational function. In order to do so they have to be highly transparent and conductive while having minimal haze and reflection. The most commonly used conductive material due to its relatively high manufacturability, cost, performance is Indium Tin Oxide (ITO). However, as ITO and many other electrode materials are not compatible with bendable or flexible displays, alternatives are printed silver nanowires or NanoWeb®, a transparent, flexible, and durable metal electrode mesh film. It can be fabricated with almost any metal material and can be used in very large, curved and flexible touch screen devices also. Other research prototypes use for example conductive gel sandwiched between two silicon layers.\n\n\n  Examples\n\n  GelTouch: Localized Tactile Feedback Through Thin, Programmable Gel\n\n  GelTouch is a 2mm transparent gel-based layer that can transition between soft and 25 times stiffer providing tactile multi-touch feedback. When activated by applying heat (&gt;32 C), it can be morphed freely and continuously, without being limited to fixed, predefined shapes. \nActivation techniques: 1) Indium Tin Oxide (ITO) as a heating element that enables tactile feedback through individually addressable taxels; 2) predefined tactile areas of engraved ITO, that can be layered and combined; 3) complex arrangements of resistance wire that create thin tactile edges. The prototype tablet contains 6x4 tactile areas, enabling a tactile numpad, slider, and thumbstick."
					}
					
				
		
				
					,
					
					"terms-data-physicalization": {
						"id": "terms-data-physicalization",
						"title": "Data Physicalization",
						"categories": "design",
						"url": " /terms/data-physicalization",
						"content": "Data Physicalizations, also known as Physical Visualization, are the physical counterpart of purely visual data visualizations. Three-dimensional, often shapeable physical representations of data provide physical metaphors that allow to explore, reason and communicate about the semantic of data.\nThe research area of Data Physicalization involves novel types of interfaces such as actuated dislays or tangible and shape-changing interfaces.\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"terms-direct-manipulation": {
						"id": "terms-direct-manipulation",
						"title": "Direct Manipulation",
						"categories": "user experience",
						"url": " /terms/direct-manipulation",
						"content": "Direct manipulation is an interaction style first coined by Ben Shneiderman in the early 1980s, when humans usually interacted with computers via the command line. In direct manipulation the objects of interest in the UI are continuosly visible, they can be acted upon physically and allow reversible, incremental actions while providing continuous feedback.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-elastic-display": {
						"id": "terms-elastic-display",
						"title": "Elastic Display",
						"categories": "technology",
						"url": " /terms/elastic-display",
						"content": "Elastic displays are shape-changing interfaces that are only temporally deformable, more precisely, they automatically return into their inital flat state after the deformation. The display allows users to give input by force-touch (e.g. pinching, pushing, folding, and twisting the display), providing them with rich haptic feedback.\n\nMost applications use rear-procection to display graphical content on the malleable surface, as it prevents users from covering the projection with their hand’s shadow while interacting. Nearly all feature the use of non-slippery, elastic fabric like for example latex, lycra and spandex. Detecting and tracking complex deformations and multi-touch on the deformable display are a remaining challenge. Recent prototypes often take advantage of the Intel RealSense or the Microsoft Kinect depth sensor to rapidly detect multi-touch input in three dimensions, offsetting the high cost and unreliability of other approaches like infrared camera-based tracking.\n\nThe large visualization and interaction space of elastic displays is appropriate for vast amounts of Zoomable 2D, Volumetric 2.5D and Spatial 3D data contained in modern information visualizations. Evaluation of existing elastic display applications revealed that interaction with the dimension of depth is especially suited to simulate physics of objects, retrace time-based changes or explore different levels of detail in the data. To make the content accessible Kammer et al. in New Impressions in Interaction Design. A Task Taxonomy for Elastic Displays propose techniques such as image sequences, pixel-based blending, vector fields and single- or multi-touch 3D . They state that elastic displays can support users to discover relationships, understand structures, search items, manipulate data, make decisions and collaborate. Additionally, Tangibles or Gravibles could be used to safe current state by retaining the shape of the surface.\n\n\n  Examples\n\n  The DepthTouch system was used to realize a product browser to search products by similarity and for interactive in-depth physics simulation. (see: DepthTouch: an elastic surface for tangible computing)\n  \n  \n\n  The FlexiWall system introduces different applications: a map viewer shows different semantic layers on geographical maps, a painting explorer allows analyzing the painting process through different radiological scans made of an art piece, and a photo browser allows local application of different image effects. Moreover, big data clustering algorithms can be investigated using either layers or a semantic zoom."
					}
					
				
		
				
					,
					
					"terms-electrophoretic-display": {
						"id": "terms-electrophoretic-display",
						"title": "Electrophoretic Display",
						"categories": "technology",
						"url": " /terms/electrophoretic-display",
						"content": "An electrophoretic display (also known as electronic ink display) is an electronic display based on the phenomenon of electrophoresis to mimic the appearance ordinary ink on paper. Negatively and positively charged pigment particles stored in microcapsules form images by applying a positive or negative electric field. Images are still visible after all power sources have been removed, because the display only consumes power whenever the image changes. However, so-called active displays are refreshed at a given rate. Just like an ordinary book or newspaper, there is no need for a backlight as the surface of an electrophoretic display reflects ambient light back to the user.\n\nFactoring in low power consumption, print-like readability and minimal thickness and weight, electrophoretic display technology can be used for the development of novel display shapes such as curved screens, foldable tablets or highly flexible, bendible surfaces.\nNote that color electrophoretic displays (e.g. Mirasol-Display, MIP-Display or electrowetting displays) currently suffer from performance issues. The low refresh rate and is also disadvantageous for devices that have high degree of user interactivity.\n\n\n  Examples\n\n  Electrophoretic display technology gained popularity from the introduction of electronic ink by E Ink Corporation. Other applications that featured the display technology include e-readers such (e.g. Amazon Kindle or Kobo eReader Touch), smartwatches (e.g. Pebble), cell phones or electronic price tags.\n\n  PaperTab  is a flexible, high-resolution and interactive paper tablet that looks and feels just like a sheet of paper."
					}
					
				
		
				
					,
					
					"terms-embodiment": {
						"id": "terms-embodiment",
						"title": "Embodiment",
						"categories": "user experience",
						"url": " /terms/embodiment",
						"content": "Embodiment is a tangible or visible form of an idea, expression or quality. Humans have a lifelong training in developing thoughts and ideas based on physical experiences. By presenting data in embodied shapes, physical and tangible information visualization therefore is able to convey information to people in a highly memorable and intuitive way.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-flexible-display": {
						"id": "terms-flexible-display",
						"title": "Flexible Display",
						"categories": "technology",
						"url": " /terms/flexible-display",
						"content": "A flexible display (also known as persistent deformed display) is a shape-changing interface that uses permanent shape deformation as form of input, e.g. bending, flexing, twisting, squeezing and pushing. While being an highly intuitive way of interaction, remaining challenges in flexible display research are to overcome limited haptic feedback and unintended display manipulations (since there are no boundaries that restrict the interaction). Most implementations of flexible displays are made of modelling clay, sand or gel that represent data.\n\n\n  Examples\n\n  GelSight uses high-resolution robot tactile sensors for estimating geometry and force. The sensor’s surface consists of soft elastomer. It directly measures its vertical and lateral deformation, which corresponds to the exact object shape and the tension on the contact surface. The contact force and slip can be inferred from the deformation as well. More information: https://www.mdpi.com/1424-8220/17/12/2762\n\n  \n\n  MudPad is able to give localized active haptic feedback by using magnetorheological (MR) fluid and an array of electromagnets to actuate the fluid. The fluid is “smart” because one of its properties - its viscosity - can be controlled by a magnetic field. MudPad is covered by a pouch filled with MR fluid. More information: https://hci.rwth-aachen.de/mudpad"
					}
					
				
		
				
					,
					
					"terms-gesture": {
						"id": "terms-gesture",
						"title": "Gesture",
						"categories": "user experience",
						"url": " /terms/gesture",
						"content": "“A gesture is a motion of the body that contains information. Waving goodbye is a gesture. Pressing a key on a keyboard is not a gesture because the motion of a finger on its way to hitting a key is neither observed nor significant. All that matters is which key was pressed”. [Kurtenbach and Hulteen]\n\nGestures are the input through which users interact with the interface of an display. But where exactly does it start and where does it end? Is it just a movement or maybe more? According to the cite from Kurtenbach and Hulteen a gesture can be defined as movement of the body that is performed to convey meaning. Meaning therefore implicitly determines the relevant components of a single gesture and sets its boundaries.\nExplore the gestural interaction space of elastic displays under gesture alphabet.\n\nGesture Classifications\n\nNote: The following compilation is not a complete collection of approaches to classify gestures that in our opinion are useful.\n\nGeneral classification of gestures by Cadoz,\ncited in Ergotic / epistemic / semiotic functions [Luciani]\n\n  Ergotic: modify environment using force\n  Epistemic : explore the environment via tactile sense\n  Semiotic : transfer information to the environment by following conventions, e.g. wave good-bye, sign language\n\n\nGeneral classification of gestures for gestural interfaces,  \nAn Intuitive Two-Handed Gestural Interface for Computer Supported Product Design [Hummels et al.]\n\n\n  predefined symbolic commands (emblems): based on technical commands\n  gesticulations representing content of speech\n  act gestures to describe the form of objects (descriptive) or transform objects (manipulative)\n\n\n“Kendon’s continuum”, classification of gestures by dependency on speech (*),\ncited in Gesture: A Psycholinguistic Approach [McNeil]\n\n\n  Gesticulations (Beat, Cohesive)\n  Language-Like (Iconic)\n  Pantomimes (Pantomimic)\n  Emblems (Deictic)\n  Sign Language (Symbolic)\n(*descending)\n\n\nClassification of semiotic gestures by Rime and Schiaratura,\ncited in Gestures in Human-Computer Interaction [Muser]\n\n\n  Deictic: pointing, e.g. using a mouse pointer\n  Motoric: marks the rhythm of speech\n  Symbolic / emblematic: contextual conventions, e.g. thumbs up\n  Iconic: represents the content of the speech, e.g. shape of an object\n  Metaphoric: illustrates abstract ideas\n\n\nGeneral classification of elastic gestures,  \nInvestigating Gestures on Elastic Tabletops [Kammer et al.]\n\nPUSH - TOUCH - PULL\n\nClassification of touch gestures for screen devices, \nMaterial Design: Types of Gestures [Google]\n\n\n  navigational gestures (move through)\n  act gestures (complete actions + use shortcuts)\n  transform gestures (transform objects)\n\n\n\n  Examples\n\n  See Elastic Gestures for gestural interaction on elastic displays."
					}
					
				
		
				
					,
					
					"terms-gravibles": {
						"id": "terms-gravibles",
						"title": "Gravible",
						"categories": "user experience",
						"url": " /terms/gravibles",
						"content": "Gravibles are tangibles that use gravity to persist deformation on the tabletop surface of elastic displays.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-lyocell": {
						"id": "terms-lyocell",
						"title": "Lyocell",
						"categories": "society",
						"url": " /terms/lyocell",
						"content": "Lyocell is a sustainable fabric used for clothing or other purposes. The fibre was further developed and is sometimes still referred to as Tencel. It consists of cellulose fibre, made from dissolving pulp and then reconstituting it by dry jet-wet spinning. Lyocell is more expensive to produce than cotton or viscose rayon but still affordable.\n\nAdvantages\n\n  elastic\n  durable\n  can simulate various textures (like suede, leather, silk)\n  high moisture absorption\n  resistant to wrinkles\n  easy to process\n  may be machine washed, drycleaned, dyed in any color\n  anti-bacterial\n\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-organic-user-interface": {
						"id": "terms-organic-user-interface",
						"title": "Organic User Interface",
						"categories": "technology",
						"url": " /terms/organic-user-interface",
						"content": "An organic user interface (OUI) is a non-flat user interface whose display may passively or actively change shape upon interaction on the surface. \nThe use of the word “organic” refers to the philosophy of organic architecture that adopts natural forms to design a better fit with human ecology. Therefore, inputs are provided through direct physical gestures mainly. Vertegaal and Poupyrev who introduced OUIs in 2008 in Organic User Interfaces focus on the user’s perception and interaction with the display to differ between three general types of OUI:\n\n\n  Flexible: Deformable displays that use shape deformation as form of input, e.g. flexible OLED\n  Shaped: non-deformable shaped displays, e.g. geometric forms or objects or everday use\n  Actuated (or kinetic): Deformable displays with a shape controlled by a computer algorithm\n\n\nExcluding non-deformable (shaped) displays from the above list, shape-changing interfaces can be considered either as a subgroup of organic user interfaces or an alternative approach to classify non-flat interface shapes concentrating on deformation properties or context of use.\n\n\n  Examples\n\n  PaperPhone was one of the first OUIs to introduce bend gestures on a real flexible screen. It featured a flexible electrophoretic display and an array of 5 bend sensors that allowed for user navigation of content. (see: PaperPhone: Understanding the Use of Bend Gestures in Mobile Devices with Flexible Electronic Paper Displays!)"
					}
					
				
		
				
					,
					
					"terms-physical-computing": {
						"id": "terms-physical-computing",
						"title": "Physical Computing",
						"categories": "technology",
						"url": " /terms/physical-computing",
						"content": "Physical computing is, in short, making interactive physical systems out of hardware and software that sense changes in the real-world environment and respond to them. Analog input from sensors is digitalized and processed to software applications or electromechanical systems (e.g. motors, LEDs) or used to control other hardware components via actuators. If software is running on an embedded microcontroller inside the system it is called embedded system. Physical computing is used in a wide range of domains and applications such as education, art, and both scientific and commercial applications.\n\n\n\n\n  Examples\n\n  I-CubeX is a system of sensors, actuators and interfaces configured by a personal computer. It uses MIDI, Bluetooth or USB for communication, making it simply for music or visual artists to create and modify musical instruments or interactive installations. See also the I-CubeX demos.\n\n  An example for physical computing with an embedded system is the popular open-source Arduino platform, developed by italian researcher Massimo Banzi and his team since 2005. Making it possible to simplay control interactive objects or to interact with software applications the platform gained great popularity in interactive art installations. A huge numebr of installations can be discovered on the official Arduino Project Hub.\n\n  The Raspberry Pi is a mini linux comupter on a SD card. Pins allow makers and hobbyists to connect electronic components, extend the capabilities with add-on boards and program physical devices in the real world, such as inputs like sensors and outputs like lights. Visit the offical website to browse a number of tutorial-like projects."
					}
					
				
		
				
					,
					
					"terms-physics-based-interaction": {
						"id": "terms-physics-based-interaction",
						"title": "Physics-Based Interaction",
						"categories": "user experience",
						"url": " /terms/physics-based-interaction",
						"content": "Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-radical-atoms-vision": {
						"id": "terms-radical-atoms-vision",
						"title": "Radical Atoms Vision",
						"categories": "design",
						"url": " /terms/radical-atoms-vision",
						"content": "The Radical Atoms Vision aims to make the physical state of Tangible User Interfaces fully consistent with the underlying digital models and change the form or properties of physical objects in real time interactions. Hiroshi Ishii and the Tangible Media Group presented the vision in 2012 to overcome the limitations of their Tangible Bits Vision that are caused by the rigid atoms the TUIs consist of in comparison to the fluid digital bits they embody. Using computationally transformable and reconfigurable material they think of the user interface as material itself and propose to call it Material User Interface (MUI).\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-rapid-prototyping": {
						"id": "terms-rapid-prototyping",
						"title": "Rapid Prototyping",
						"categories": "technology",
						"url": " /terms/rapid-prototyping",
						"content": "Rapid prototyping is an umbrella term for a group of techniques that allow to quickly fabricate prototypes or scale models based on three-dimensional CAD data. It is used to identify weaks in an early product development state and to rapidly create demonstration material, minimizing production costs. Because objects are built by adding material layer by layer the process is also known as additive manufactoring. Common rapid prototyping techniques are for example 3D printing of CAD data, Space Puzzle Molding, Laminated Object Modelling or Contour Crafting.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-reality-based-interaction": {
						"id": "terms-reality-based-interaction",
						"title": "Reality-Based Interaction",
						"categories": "user experience",
						"url": " /terms/reality-based-interaction",
						"content": "Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-shape-changing-interface": {
						"id": "terms-shape-changing-interface",
						"title": "Shape-Changing Interface",
						"categories": "technology",
						"url": " /terms/shape-changing-interface",
						"content": "Shape-changing Interfaces are interactive or computationally controlled devices that are able to transform into any shape or materiality. They use the device’s physical shape as input and output thus providing direct, everyday world interaction experience und inherent support of multi-user interaction. In other words, Shape-changing Interfaces exploit our haptic and kinaestetic senses and instinctive perception of physical forms.\nThe term shape-changing interface is an umbrella term for various interface types. In Analysis and Classification of Shape-Changing Interfaces for Design and Application-based Research Sturdee and Alexander differ between Enhanced 2D, Bendable, Paper &amp; Cloth, Elastic &amp; Inflatable, Actuated, Liquid, Malleable and Hybrid Interfaces.\n\n\n\nIn Grand Challenges in Shape-Changing Interface Research Alexander et al. also propose an alternative classification for Shape-changing Interfaces with a view to the context of use. The interface might adapt to specific tasks, users or environments, communicate information through shape-change, augment users, simulate objects or simply be decorative. Regarding the deformation one can distinguish between orientation, form, volume, texture, viscosity, spatiality, adding/subtracting, permeability.\n\nBest Practices cover practical implications of current challenges that have been identified in shape-changing interface research.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-shape-memory-alloy": {
						"id": "terms-shape-memory-alloy",
						"title": "Shape Memory Alloy",
						"categories": "technology",
						"url": " /terms/shape-memory-alloy",
						"content": "Shape memory alloys (SMA) are an actuator technique for shape-changing displays using metal alloys. Electrical actuation heats up the material which then undergoes temperature driven phase transformation between two different crystal forms (austenite = higher temperature phase / martensite = lower temperature phase).  A change in crystal structure results in dimensional changes that are typically between 1% and 8%. The special property of SMAs is that, unlike most crystal transformations, the process is fully reversible. Besides a range of iron-based and copper-based alloys the two most prevalent SMAs are copper-aluminium-nickel (cheap) and nickel-titanium (NiTi) (more stable but superior thermo-mechanic performance). Both of them can be manufactured to almost any shape and size.\n\nThe challenges in designing SMA applications are to overcome their limitations, which include a relatively small usable strain, low actuation frequency, low controllability, low accuracy and low energy efficiency. SMA deactuation for example is typically slower than actuation, because it occurs by heat transfer to the ambient environment.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-smart-materials": {
						"id": "terms-smart-materials",
						"title": "Smart Materials",
						"categories": "technology",
						"url": " /terms/smart-materials",
						"content": "Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-smart": {
						"id": "terms-smart",
						"title": "S.M.A.R.T.",
						"categories": "design",
						"url": " /terms/smart",
						"content": "The letters of S.M.A.R.T. acronym give criteria which help setting objectives by pushing concrete statements, for example in project management. To take benefit from the S.M.A.R.T. criteria it is important to combine it with an action plan afterwards.\n\nNote: In certain situations this is not realistic or even dilutes the definition of the objective if you quantify all the criteria. Also, choosing certain combinations of these labels can cause duplication, you may take it as an offer from which you can choose.\n\nS. Specific (or strategic) – Be clear and specific with what you want to achieve.\nM. Measurable (or motivating) – Quantify or at least suggest an indicator of progress. \nA. Achievable (or attainable / assignable) – Specify who will do it.\nR. Relevant (or realistic) – State what results can realistically be achieved, given available resources.\nT. Time-bound (ot trackable) – Specify when the result(s) can be achieved.\n\n\n  Examples\n\n  “We will have constructed a functional prototype of an elastic display that reacts upon gestural input in a visible ways within four months after three months of intense study of tracking technologies, software frameworks and surface materials.”\n\n  Specific:\nThe goal of constructing a functional prototype is well-defined.\nMeasurable:\nSuccess can be measured by the decisions made in favour of a particular method of implementation, construction plans and improvements.\nAchievable:\nThe goal setters will have the appropriate skills for the task due to their prior experience and intense study.\nRelevant:\nThe goal setters are planning to build an innovative application in the field of industry they are currently working in.\nTime-based:\nThe goal setters have set a deadline to achieve their objective within the seven months following kick-off."
					}
					
				
		
				
					,
					
					"terms-tangible-bits-vision": {
						"id": "terms-tangible-bits-vision",
						"title": "Tangible Bits Vision",
						"categories": "design",
						"url": " /terms/tangible-bits-vision",
						"content": "The Tangible Bits Vision was developed by Hiroshi Ishii and Tangible Media Group in 1997 who seeked to take advantage of the human skills to sense and manipulate the physical environment in order to explore digital information spaces. They proposed the concept of Tangible User Interfaces (TUIs) to go beyong the “painted” bits on Graphical User Interfaces (GUIs). Data (=bits) is given a tangible, physical form (=atoms), including for example directly graspable objects and augmented surfaces as well as ambient light, sound, airflow, and water movement.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-tangible-user-interface": {
						"id": "terms-tangible-user-interface",
						"title": "Tangible User Interface",
						"categories": "technology",
						"url": " /terms/tangible-user-interface",
						"content": "(previously known as Graspable User Interface)\n\nThe term Tangible User Interface (TUI) was first introduced by MIT’s Tangible Media Group (led by Hiroshii Ishii) who are also well-known for their visions of Tangible Bits and Radical Atoms. It describes an interactive user interface based on physical embodiment of digital information as tangible objects. These so-called tangibles are used as well as controls (input) and representations (output), making data and the impact of interaction on data literally graspable. Users are provided with parallel feedback loops: physical, passive haptic feedback informs users that a certain physical manipulation is complete; and digital, visual or auditory feedback informs users of the computational interpretation of their action. Interactions and object manipulations are tracked by cameras placed behind the surface or using touch screens with electrically conductive materials.\n\nApplication areas for TUIs are collaboration, social commuication, learning, support of planning and problem solving, programming and simulation tools, information visualization and exploration, entertainment, performance and music. The design space of TUIs includes 2D / 3D space and virtual, augmented or mixed reality applications.\n\nAccording to Ullmer at al. in Token+constraint systems for tangible interaction with digital information the 3 main approaches of TUIs are\n\n\n  tangible objects with interactive (tabletop) surfaces,\n  constructive assemblies of modular connecting blocks (similar to the model of physical construction kits) and\n  token–constraint systems with physical “complementarities” such as plug and socket (tokens represent digital information or interactions of an application and constraints limit the interaction space)\n\n\n\n\n\n  Examples\n\n  One early example is Durrell Bishop’s Marble Answering Machine, which physicalizes incoming voice messages as marbles. With each new voice message marbles fall automatically\nin a container. Users can move marbles to different containers to perform actions, such as listening to a message or call back. The Marble Answering Machinge is consodered to be an token-constraint TUI.\n\n  Reactable is a commercial modular synthesizer with a translucent tabletop TUI designed for hotels, museums or music live performances. Sound effects are controlled by placing or rotating tangibles with painted symbols on the display, each of them representing a different synth module. The table displays graphics such as waveforms or circles as the tangibles placed. Reactable has an app successor called Rotor that combines standard multi-touch capabilities with tangible input."
					}
					
				
		
				
					,
					
					"terms-tangible": {
						"id": "terms-tangible",
						"title": "Tangible",
						"categories": "user experience",
						"url": " /terms/tangible",
						"content": "A Tangible is a thing that is perceptible by touch, making data and the impact of interaction on data literally graspable. In tangible user interfaces they can be used to control the input and represent the output of an interaction, e.g. a volume control that informs the user about the adjusted volume through its state.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-wimp-interface": {
						"id": "terms-wimp-interface",
						"title": "WIMP Interface",
						"categories": "technology",
						"url": " /terms/wimp-interface",
						"content": "An interface consisting of windows, icons, menus, and pointers (WIMP) using predominantly mouse and keyboard as interaction styles.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"terms-zoomable-user-interface": {
						"id": "terms-zoomable-user-interface",
						"title": "Zoomable User Interface",
						"categories": "technology",
						"url": " /terms/zoomable-user-interface",
						"content": "According to Hornbæk et al. in Navigation Patterns and Usability of Zoomable User Interfaces With and Without an Overview a zoomable user interface (ZUI) is an interface that organizes data objects in space and scale and allows users to interact directly with the information space. Typical interaction techniques of ZUIs are panning (change the visible area of information space) and zooming (control scale of the information space to explore greater levels of detail in the data). Most common is geometric zoom, where the scale linearly determines the apparent size of the object. However, in so-called semantic zooming, often used with maps, some features of the visible objects (e.g. text labels) may preserve their original size while others reveal more details by scaling. In density zooming a constant number of objects is shown, determining the level of detail.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
		
				
					,
					
					"concepts-chart-types": {
						"id": "concepts-chart-types",
						"title": "Chart Types",
						"categories": "design",
						"url": " /concepts/chart-types",
						"content": "Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"concepts-color-theory": {
						"id": "concepts-color-theory",
						"title": "Color Theory",
						"categories": "design",
						"url": " /concepts/color-theory",
						"content": "Examples\n\n  ColorDrop\n\n  Adobe Color\n\n  Color Tool - Material Design\n\n  Mozilla Accessibility Inspector\n\n  Vision Deficiencies in Chrome"
					}
					
				
		
				
					,
					
					"concepts-emulator": {
						"id": "concepts-emulator",
						"title": "Emulator",
						"categories": "technology",
						"url": " /concepts/emulator",
						"content": "We are currently developing an emulator for elastic displays. We hope that you can test it here soon.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"concepts-gestalt-principles": {
						"id": "concepts-gestalt-principles",
						"title": "Gestalt Principles",
						"categories": "user experience",
						"url": " /concepts/gestalt-principles",
						"content": "The Gestalt Principles of Visual Perception are a set of rules based on psychological theories of human perception. They were developed in the 1920s by German psychologists Max Wertheimer, Kurt Koffka and Wolfgang Kohler who stated that the human brain is wired to see structure, logic, and patterns in order to make sense of the world. In other words, humans want to see structure by default. The principles are widely used in modern design asthey help designers to determine which design elements effectively catch the user’s attention, and create easy-to-use, intuitive products. The six most common rules are listed below.\n\n\n  Figure-ground\n  Humans organize their perception by interpreting closed shapes to be figures on a ground.\n\n\n\n  Proximity\n  Elements which are near to each other tend to be perceived as group.\n\n\n\n  Common fate\n  Elements pointing or moving in the same direction are perceived as group.\n\n\n\n  Similarity\n  Similar looking elements tend to be perceived as group.\n\n\n\n  Continuity\n  Humans recognize oriented elements as perceptual wholes and follow them in visual flow.\n\n\n\n  Closure\n  Humans tend to automatically fill the gaps between visual elements to complete shapes."
					}
					
				
		
				
					,
					
					"concepts-gesture-alphabet": {
						"id": "concepts-gesture-alphabet",
						"title": "Gesture Alphabet",
						"categories": "user experience",
						"url": " /concepts/gesture-alphabet",
						"content": "We propose a gesture alphabet to describe gestures that are used to interact with an elastic display. The alphabet contains 7 basic hand postures which can be classified into single finger, multiple finger and hand postures, reflecting the area touched on the display when performing an interaction. According to Kammer et al.’s classification in Investigating Gestures on Elastic Tabletops, elastic gestures also differ in the type of deformation they cause on the display (push, touch or pull). Furthermore, they can be static, dynamic or circular using one or both hands. In real application scenarios, several users often interact with the application simultaneously.\n\n\n\nResearch Background\n\nGestures performed on an elastic display are a subset of gestures described in HCI research. For example, interaction does not contain gestures performed in mid-air or beat gestures marking the rhythm of speech. Elastic displays are instead suitable for types of gestures that can be performed by physically touching and shaping a malleable surface. In research, such gestures are most often referred to as deictic gestures (pointing), iconic gestures (follow conventions to illustrate speech such as thumbs up) and symbolic/emblematic gestures (independent of speech such as sign-language).\n\nThe gesture alphabet is derived from 27 single- and both-handed gestures defined by Troiano et al. in User-Defined Gestures for Elastic, Deformable Displays) and a 10 gesture collection by Dand and Helmsley in Obake: interactions with a 2.5D elastic display. When combining the two collections we adopted only those gestures which in our experience have proven to be useful.\n\n\n  Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"concepts-interaction-techniques": {
						"id": "concepts-interaction-techniques",
						"title": "Tasks",
						"categories": "user experience",
						"url": " /concepts/interaction-techniques",
						"content": "User tasks describe actions users perform in interactive visualizations. Diverse appraoches have been made to somehow formalize these actions, most of them taking into account at least the abstract motivation (why) and concrete action (how) of a task. Descriptions differ for example in the level of detail, in the way they reflect the contextual embedding of the task (e.g. data, context, user) and can either be top-down or bottom-up-approaches.\n\n\n  Examples\n\n  \n    User Story in Agile Software Development\n    Task Abstraction by Tamara Munzner"
					}
					
				
		
				
					,
					
					"concepts-materiality": {
						"id": "concepts-materiality",
						"title": "Materiality",
						"categories": "design",
						"url": " /concepts/materiality",
						"content": "…\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"concepts-moodboard": {
						"id": "concepts-moodboard",
						"title": "Mood Board",
						"categories": "design",
						"url": " /concepts/moodboard",
						"content": "A mood board is a visual collage of assets (images, typography,…) and materials intended to communicate the style, voice, direction, basic tone or language of a particular design, brand, or project. Being an effective communication tool it can be used to convey a general idea or feeling about a particular topic in early states of creation. A mood board may be physical or digital, can be based upon a set topic or can be any material chosen at random.\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"concepts-paper-prototyping": {
						"id": "concepts-paper-prototyping",
						"title": "Paper Prototyping",
						"categories": "design",
						"url": " /concepts/paper-prototyping",
						"content": "A simple variant of the prototype production is the paper prototyping. It only requires some paper or a whiteboard and a pen. Ideas can be recorded and collected directly. Paper prototyping covers the essential key points of prototyping. The prototype can be modified directly at any time. Changes are directly visible and not hidden.\n\nIn the example pictures you can see how paper prototyping is used in combination with the created prototype of an Elastic Display. You can find the article about the creation of an Elastic Display prototype here “How to build a prototype”.\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"concepts-persona": {
						"id": "concepts-persona",
						"title": "Persona",
						"categories": "user experience",
						"url": " /concepts/persona",
						"content": "Personas are individual model characters that represent (extreme) user types of a service or product. They help you to understand the users’ needs, experiences, behaviours and goals. Therefore, personas can guide ideation processes and help you to create a good user experience. Working with personas has become standard practice within many human centred design disciplines to collate research and personify trends and patterns in the data. It is very common to couple personas with the decription of scenarios that usually start by placing the persona in a specific context with a problem they want to or have to solve.\n\nCreating a Persona\n\nResearch \nThe first step involves data aggregation about the users and the context, e.g. via surveys, interviews or statistics.\n\nCreate individual characters\nNext, data patterns are used to model few fictional individuals. Often, they represent power/lead users, A persona, like a “real person”, consists of a name and a corresponding photo, in order to have a realistic picture in your mind while working. Commonly used features are:\n\n\n  Sociodemographic (age, sex, marital status, social background)\n  Socio-economic data (income, occupation, education, social background, social status)\n  Geographical information (place of residence, origin, regional/local/international orientation)\n  Psychographic characteristics (attitudes and opinions, values and status awareness, preferences and hobbies, but also dislikes, habits, motivations, aesthetic feelings, goals)\n  Product-related characteristics (wishes, expectations, needs)\n  Consumer behaviour (brand loyalty, purchasing range, repurchase rate, price sensitivity, etc.)\n\n\nA persona is usually recorded as profile or in a narrative style in continuous text an may be accompanied by a scenario. The poster below is taken from Lene Nielsen’s article Personas [Nielsen]. It decribes a more holistic way of developing personas.\n\n\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"concepts-projection": {
						"id": "concepts-projection",
						"title": "Projection",
						"categories": "technology",
						"url": " /concepts/projection",
						"content": "Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"concepts-scenario": {
						"id": "concepts-scenario",
						"title": "Scenario",
						"categories": "user experience",
						"url": " /concepts/scenario",
						"content": "A scenario is a believable story that describes specific situations that trigger use of what you are designing as well as significant acitivities and the personal experience of persona. Scenarios can bring to life your personas by featuring them in the role of a user, usually by placing the persona in a specific context with a problem they want to or have to solve. Scenarios can be used to derive weighted requirements in product / service development process that reflect the target users’ needs.\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"concepts-software-framework": {
						"id": "concepts-software-framework",
						"title": "REFLEX Software Framework",
						"categories": "technology",
						"url": " /concepts/software-framework",
						"content": "Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"concepts-stop-motion": {
						"id": "concepts-stop-motion",
						"title": "Stop Motion",
						"categories": "design",
						"url": " /concepts/stop-motion",
						"content": "Stop motion is a simple form of animation and is used to create movies or short videos. Each scene is photographed individually and with each additional image the objects are minimally changed to simulate the movement of the objects.\n\nIn the example pictures you can see how stop motion is used in combination with the created prototype of an elastic display. You can find the article about the creation of an elastic display prototype here: Design Protoyping.\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"concepts-sustainable-materials": {
						"id": "concepts-sustainable-materials",
						"title": "Sustainability",
						"categories": "society",
						"url": " /concepts/sustainable-materials",
						"content": "Designing, prototyping and implementing shape-changing interfaces comes along with a high material consumption. Some of it already becomes waste after a short time what is best to avoid. In other words: The most sustainable material is the one that has never been used. Therefore, digitalize the design process if possible, hold online workshops, use emulators for prototyping, and reuse materials. If the use of new materials is necessary, sustainable materials that can be recycled and biodegrades should be preferred.\n\n6 R’s of Sustainability\n\n\n  Reduce\n  Reuse\n  Recycle\n  Refuse\n  Rethink\n  Repair\n\n\n\n  Examples\n\n  Sustainable Fabrics\n\n  As it comes to elastic displays, the fabric on the surface must have sufficient elasticity and durability to withstand all user inputs and long-term installations. An option to consider is lyocell (also: tencel), which is not only elastic and durable, but also anti-bacterial and available in various textures.\n\n  \n\n  Digital Prototyping\n\n  Currently, we are developing an emulator for elastic displays. We hope, that it can be tested here soon."
					}
					
				
		
				
					,
					
					"concepts-tracking": {
						"id": "concepts-tracking",
						"title": "Tracking",
						"categories": "technology",
						"url": " /concepts/tracking",
						"content": "Examples\n\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
		
				
					,
					
					"design-prototyping": {
						"id": "design-prototyping",
						"title": "Design Prototyping",
						"categories": "design",
						"url": " /design-prototyping/",
						"content": "Design Prototyping\nIt is helpful to build a prototype in order to get a feeling for elasticity, handling and the interaction possibilities of fabrics in relation to the elastic display. This is helpful in the beginning and especially when the possibilities to work directly on the elastic display are limited. A self-built prototype makes it easier to get started. In terms of possible designs, functions or navigation options, the prototype gives you first, but most importantly, essential impressions that are necessary to get a feel for how to work with an elastic display. The following is a list of the required materials and short instructions for creating a prototype of an elastic display.\n\nList of materials:\n\n  Picture frame / wooden frame (width 52cm / height 42cm)\n  Fabric (which is larger and wider than the frame)\n  Staple gun (or nails and a hammer)\n\n\nExecution\nTake the frame and put your fabric over it. Fix the fabric on one long side. Then pull the fabric on the opposite long side slightly tighter and fix this side as well. Repeat this procedure for the two remaining sides.\n\nTo see how you can work with the elastic display prototype take a look at the following articles: Paper-Prototyping, Stop-Motion.\n\n\n  Examples"
					}
					
				
		
				
					,
					
					"designing-application-and-content": {
						"id": "designing-application-and-content",
						"title": "Designing Application and Content",
						"categories": "design",
						"url": " /designing-application-and-content/",
						"content": "Designing Application and Content\nThere is a significant challenge in the ‘when’, ‘what’, and ‘how’ of the design and implementation of applications and content. According to Alexander et al. in Grand Challenges in Shape-Changing Interface Research we can break this challenge into the four parts described below.\n\n\n  \n    When should we apply shape-change?\nSometimes there is a clear benefit from using physically-dynamic interfaces in interaction scenarios, but sometimes traditional interfaces should be used instead. First, it’s a good idea to clarify the tasks users might want to solve by interacting with your application by doing a task abstraction. Next, you can draft a traditional and a physically-dynamic interface to solve these tasks and compare both approaches.\n  \n  \n    What shape-changes should we apply? \nKey benefits of shape-changing interfaces is their ability to transform into a broad variety of shapes or forms. The space of possible shapes has to be designed with respect to the meaning it conveys, i.e. what are the semantics of a specific shape change? Currently there is a lack of understanding as to what types of change should occur in more abstract or generic circumstances (where shape may not naturally represent content).\n  \n  \n    What applications should we build?    \nThis is about identifying and exploring key application domains that provide clear benefits and routes to end-user engagement. Each SCI technology such as an actuated, flexible, elastic or embedded display is suited for specific domains and “killer applications”. Read about the advantages and disadvantages of each technological approach and discuss which one is best suited.\n  \n  \n    How do we design the content for those applications?  \nIn an early state it will do the trick to use rather general brainstorming techniques to identify possible application scenarios, i.e. by using Mindmaps or Picture Collections. Later on, use Personas and Scenarios to bring the needs of the user into harmony with the application context. Before the application is implemented we suggest to make use of an appropriate prototyping technique such as using an emulator to test the application’s behaviour.\n  \n\n\n\n  Examples\n\n  Content Design for Elastic Display Application\n  To design the content for a layer-based application on an elastic displays, we conducted an online workshop with MIRO. The application focuses on the testing of possibilities for collaboration, visualization, data manipulation and persistence, linking of data as well as marking, zoom and filtering. For this purpose it had to be answered whether the application should be realized as a table or wall display and which data would support our particular task.\n\n  Outline. Prior to the workshop, a mood board with possible topics was created for inspiration. In a mixture of both individual and collaborative free drawing on digital canvas, we identified four application domains in which layered data is used in collaborative contexts:\n  \n    urban planning\n    museums / art\n    climate\n    data management\n  \n\n  \n\n  Results. Using dot voting technique, we finally decided on urban planning scenario and optional integrate climate issues. Art and data management were considered to be suitable for the visualization of abstract data in a separate use case."
					}
					
				
		
				
					,
					
					"designing-for-temporality": {
						"id": "designing-for-temporality",
						"title": "Designing for Temporality",
						"categories": "design",
						"url": " /designing-for-temporality/",
						"content": "Designing for Temporality\nShape-changing interfaces require temporal design: there is an important challenge in translating behavioural sketches and functional descriptions of behaviour into actual designs. While sketches and prototypes of static forms provide representations that are visually and tangibly comparable by multiple people simultaneously, dynamic form has temporal aspects that are difficult to compare in parallel. This makes traditional methods such as design critique more difficult to perform. In particular, the direct interaction a user has with a shape-changing interface offers a unique experience to that person; there is not yet a language that supports the articulation of properties, experiences, or sensations, such as colour or material properties in traditional product design.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"integrating-artefact-and-interaction": {
						"id": "integrating-artefact-and-interaction",
						"title": "Integrating Artefact and Interaction",
						"categories": "design",
						"url": " /integrating-artefact-and-interaction/",
						"content": "Integrating Artefact and Interaction\nWith shape-changing interfaces, designers will be challenged to develop devices that are satisfying both in the form and dynamics of interaction between the artefact and the people interacting with it. The usability and aesthetics will be inextricably linked, with the aim of designing shape-changing materials that engage the body as well as our mind.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"developing-sustainable-interfaces": {
						"id": "developing-sustainable-interfaces",
						"title": "Developing Sustainable Interfaces",
						"categories": "society",
						"url": " /developing-sustainable-interfaces/",
						"content": "Developing Sustainable Interfaces\nShape-changing interfaces are a ‘double-edged sword’ for sustainability. The combination of physical actuation components, display surfaces, and electronics, pose an increased demand on natural resources, and increased challenges for recycling, and later re-use beyond those already present in consumer-level electronics. Addressing these resource challenges are essential for the long-term viability of shape-changing interfaces and the health of our environment.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"legislating-technological-innovation": {
						"id": "legislating-technological-innovation",
						"title": "Legislating Technological Innovation",
						"categories": "society",
						"url": " /legislating-technological-innovation/",
						"content": "Legislating Technological Innovation\nThe regulatory and ethical implications of the development of shape-changing interfaces will impact the long-term adoption of this technology, therefore also its longterm development.\nShape-changing interfaces pose a number of safety and ethical risks that without suitable regulation may result in rejection by end-users or widespread bans by government.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"combining-miniaturization-with-resolution": {
						"id": "combining-miniaturization-with-resolution",
						"title": "Combining Miniturization With Resolution",
						"categories": "technology",
						"url": " /combining-miniaturization-with-resolution/",
						"content": "Combining Miniturization With Resolution\n\nA significant challenge remains in the availability of small form-factor, minimal weight, and high resolution actuators. In line with more general computing trends, shape-changing interfaces are moving from stationary to mobile to wearable form factors [1, 46], and from rigid to flexible to stretchable and even floating shapes. The use of electromechanical actuators, as is common in many systems (e.g. inFORM, PinWheels, the BMW Kinetic sculpture), often results in large, heavy, and immobile setups that are not compatible with these demands. In addition, enduser expectations of current interactive systems will demand high-resolution output—Humans’ haptic and visual perception still far exceeds that possible in shape-changing interfaces. However, increasing the shape resolution tends to considerably complicate the technical setup.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"considering-non-functional-requirements": {
						"id": "considering-non-functional-requirements",
						"title": "Considering Non-functional Requirements",
						"categories": "technology",
						"url": " /considering-non-functional-requirements/",
						"content": "Considering Non-functional Requirements\nEnergy consumption is a significant challenge in actuated systems, particularly in mobile or wearable solutions which must be self-contained. Today’s shape-changing interfaces are usually tethered; if mobile, they typically use large batteries or have short battery life-spans that would be prohibitive in realistic use settings. Safety and Compliance are also significant challenges to address before placing actuated objects in users’ hands. Robotics researchers are now moving beyond traditional robotic arms, wheeled platforms and humanoids to explore a wide variety of different form factors, especially influenced by the goal of bringing robots out of the industrial setting into closer proximity to humans.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"integrating-io-modalities": {
						"id": "integrating-io-modalities",
						"title": "Integrating I/O Modalities",
						"categories": "technology",
						"url": " /integrating-io-modalities/",
						"content": "Integrating I/O Modalities\nToday’s shape-changing interfaces typically focus on shape input and output, with less emphasis on other modalities—for instance, visual output is often realised by projection mapping or low resolution LEDs. While this is acceptable for early research prototypes, successful real-world interfaces will demand additional input and output modalities. This includes high-resolution touch sensing, in-place visual output, adjustable material properties and accurate sensing of the device’s physical shape. Without this core integration, shapechanging interfaces will fail to realise their full potential.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
				
					,
					
					"using-toolkits-for-prototyping": {
						"id": "using-toolkits-for-prototyping",
						"title": "Using Toolkits for Prototyping",
						"categories": "technology",
						"url": " /using-toolkits-for-prototyping/",
						"content": "Using Toolkits for Prototyping\nPrototyping Elastic Displays is challenging because it involves complex electronics as well as mechanical engineering. Specific use contexts may require different actuation approaches. What are suitable tools to test complex Elastic Display applications in an early development state?\n\nWe describe prototyping toolkits on three technological layers that can lower the barrier to implementation of classic interfaces:\n\n  a standard platform for hardware prototyping, dealing with some aspects of actuation\n  a cross-platform software layer for applications and\n  tools for end-user programming\n\n\n\n  followed up by linked explanations on different possibilities to overcome the challenge, for example Physical Programming, 4D Printing, Rapid Prototyping, electromechanical/pneumatic/hydraulic actuation, smart materials\n  (optional) decision helper\n\n\n\n  Examples\n  Rapid Prototyping of Structural Electronics\n  [DOI 10.1109/ACCESS.2014.2311810]"
					}
					
				
		
				
					,
					
					"identifying-contexts-of-use": {
						"id": "identifying-contexts-of-use",
						"title": "Identifying Contexts of Use",
						"categories": "user experience",
						"url": " /identifying-contexts-of-use/",
						"content": "Identifying Contexts of Use\nCurrent research in shape-changing interfaces is limited by the complexity of hardware (as described earlier) which results in many devices being fragile, hard to replicate, and not suitably robust for long term use. One consequence is that in-situ evaluations of shape-change with real tasks are rare. Such evaluations will help to assess suitable contexts of use, the fit between tasks and interfaces, and issues around the cultural appropriation of shape-change.\n\n\n  Examples\n  HNF Paderborn\n\n  Since October 2018, the exhibition of the HNF Paderborn\ncomputer museum presents an elastic display. Visitors can use it to try out a physics simulation, steer a space ship in distress or influence a swarm of particles."
					}
					
				
		
				
					,
					
					"understanding-ux-factors": {
						"id": "understanding-ux-factors",
						"title": "Understanding UX Factors",
						"categories": "user experience",
						"url": " /understanding-ux-factors/",
						"content": "Understanding UX Factors\nMost evaluations of shape-change concern an entire system. To deepen evaluation we must isolate the factors and outcomes of different aspects of these systems. Key factors to consider are the experience of different transformations among shapes, the impact of using shape-change as it unfolds, and interacting. Other key factors to consider are the influence of scale on experience as well as the learnability and naturalness of interaction.\n\n\n  Examples\n  There is no example yet. Feel free to  edit this page."
					}
					
				
		
	};
</script>
<script src="/sci-knowledge-base/assets/js/lunr.min.js"></script>
<script src="/sci-knowledge-base/assets/js/search.js"></script>


<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>

<script>
$(document).ready(function() {

    var toc = $('#TOC');

    // Select each header
    sections = $('.td-content h1');
        $.each(sections, function(idx, v) {
            section = $(v);
            var div_id = $(section).attr('id');
            var div_text = section.text().split('¶')[0];
            var parent = $("#" + div_id)
            var content = '<li id="link_' + div_id + '" class="md-nav__item"><a class="md-nav__link" href="#' + div_id + '" title="' + div_text +'">' + div_text +'</a></li>';
            $(toc).append(content);

            // Add section code to subnavigation
            var children = $('<nav class="md-nav"><ul class="md-nav__list"></nav></ul>')
            var contenders = $("#" + div_id).nextUntil("h1");
            $.each(contenders, function(idx, contender){
               if($(contender).is('h2') || $(contender).is('h3')) {
                   var contender_id = $(contender).attr('id');
                   var contender_text = $(contender).text().split('¶')[0];
                   var content = '<li class="md-nav__item"><a class="md-nav__link" href="#' + contender_id + '" title="' + contender_text +'">' + contender_text +'</a></li>';
                   children.append(content);
                }
             })
             $("#link_" + div_id).append(children);
        });
    });
</script>

<script>
var headers = ["h1", "h2", "h3", "h4"]
var colors = ["red", "orange", "green", "blue"]

$.each(headers, function(i, header){
    var color = colors[i];
    $(header).each(function () {
        var href=$(this).attr("id");
        $(this).append('<a class="headerlink" style="color:' + color + '" href="#' + href + '" title="Permanent link">¶</a>')
    });
})
</script>



	
              
           </div>
          </main>
        </div>
      </div>
      <footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        

</div>
<div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="" aria-label="GitHub" data-original-title="GitHub">
    <a class="text-white" target="_blank" href="https://github.com/visualengineers/sci-knowledge-base">
      <i class="fab fa-github"></i>
    </a>
  </li>
</ul>
</div>
<div class="col-12 col-sm-4 text-center py-2 order-sm-2">
  <small class="text-white">© 2019  All Rights Reserved</small>
  
  <p class="mt-2"><a href="/about/">About Docsy</a></p>	
      </div>
    </div>
  </div>
</footer>

    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
<script src="/sci-knowledge-base/assets/js/main.js"></script>

  </body>
</html>
