---
layout: concept
title: Set of Gestures for Elastic Displays
description: set of gestures in interactive visualizations
---
*"A gesture is a motion of the body that contains information. Waving goodbye is a gesture. Pressing a key on a keyboard is not a gesture because the motion of a finger on its way to hitting a key is neither observed nor significant. All that matters is which key was pressed".* [Kurtenbach and Hulteen]

Gestures are the input through which users interact with the interface of an display. But where exactly does it start and where does it end? Is it just a movement or maybe more? According to the cite from Kurtenbach and Hulteen a gesture can be defined as **movement of the body that is performed to convey meaning**. Meaning therefore implicitly determines the relevant components of a single gesture and sets its boundaries.

### Types of Gestures
Numerous approaches exist to classify gestures. We use Cadoz' coarse-grained approach of functional classification of hand gestures and combine it with a somehow settled sub-division of semiotic gestures as these are the gestures that have been used in HCI mostly.

- **Ergotic** : modify the environment, e.g. [direct manipulation]({{ site.baseurl }}/terms/direct-manipulation), shape pottery
- **Epistemic** : get knowledge from the environment, e.g. explore materiality via tactile sense
- **Semiotic** : convey information to the environment following conventions, e.g. wave good-bye, sign language 
    - **Deictic**: pointing, e.g. using a mouse pointer
    - **Motoric**: marks the rhythm of speech 
    - **Symbolic / emblematic**: contextual conventions, e.g. thumbs up
    - **Iconic**: represents the content of the speech, e.g. shape of an object
    - **Metaphoric**: illustrates abstract ideas

### Set of Gestures for Elastic Displays
Gestural interaction on elastic displays includes users touching and shaping an elastic surface with their hands. The user's intention to "tell" the display something meaningful creates the boundaries that define start and end of a single gesture. (Note: Under [tracking technologies]({{ site.baseurl }}/concepts/tracking-technologies) you can find more on technical gesture recognition, derived from the user-defined gesture set.)

Compared to traditional HCI elastic displays enlarge the space of ergotic and epistemic gestures, as users actively shape the display surface in depth and are provided with rich haptic feedback. Among semiotic gestures elastic displays make use of deictic, symbolic, emblematic and iconic gestures only as these are the ones that can be performed by physically touching and shaping a malleable surface.

Several attempts have been made to collect, categorize and describe the gestural input modalities for elastic displays. In [User-Defined Gestures for Elastic, Deformable Displays]({{ site.baseurl }}/resources/#references) Troiano et al. identified 29 single or both-handed gestures users prefer to perform on elastic, deformable displays. Kammer et al. suggest to differ between push, touch and pull gestures ([Investigating Gestures on Elastic Tabletops]({{ site.baseurl }}/resources/#references). The video [Obake: interactions with a 2.5D elastic display]({{ site.baseurl }}/resources/#links) contains a collection of gestural interactions on elastic 2.5D displays.

TROIANO (gestures and preferences):
1. Push 18 
2. Drag 12 
3. Expand 9 
4. Grab 9 
5. Pinch 8 
6. Pull 6 
7. Hold 5 
8. Rotate 3 
9. Shrink 3 
10. Draw a shape 3 
11. Swipe 3  
12. Tap 3 
13. Twist 2 
14. Squeeze 2 
15. Slide 1 
16. Stretch 1 
17. Gather 1 
18. Release 1
19. Lasso 0,9 
20. Punch 0,7 
21. Tilt 0,6 
22. Follow the contour 0,4 
23. Slice 0,3 
24. Throw 0,3 
25. Draw a line 0,2 
26. Slingshot 0,2
27. Round a shape 0,1 
28. Rub 0,1 
29. Spread 0,1 

OBAKE:
1. Intrude (more)
2. Extrude (more)
3. S-bend
4. Stich
5. Compress
6. Pull (shapes)
7. Push (shapes)
8. Prod
9. Friction
10. Warp

## Own catalogue
...

